[[11/15/2018 06:05:35 PM]] 
new run with parameters:
{'USE_CHARS': True,
 'batch_size': 128,
 'causal': False,
 'char_representation_method': 'BI-LSTM',
 'checkpoint_dir': 'checkpoints_wo_causal_cnn_char',
 'dim_char': 100,
 'dim_word': 300,
 'early_stopping_steps': 3000,
 'enable_parameter_averaging': False,
 'filter_widths': 3,
 'grad_clip': 5,
 'hidden_size_char': 100,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.001,
 'log_dir': 'logs',
 'log_interval': 1,
 'loss_averaging_window': 100,
 'max_seq_len': 36,
 'max_word_length': 54,
 'metric': 'f1',
 'min_steps_to_checkpoint': 500,
 'nchars': 77,
 'ntags': 3,
 'num_channels': [300, 250, 200, 150, 100, 50],
 'num_restarts': 0,
 'num_training_steps': 15000,
 'num_validation_batches': 10,
 'nwords': 24475,
 'optimizer': 'adam',
 'prediction_dir': 'predictions_wo_causal_cnn_char',
 'reader': <__main__.DataReader object at 0x7f6aa8c8c518>,
 'regularization_constant': 0.0,
 'trainable_embedding': False,
 'use_evaluation_metric_as_early_stopping': True,
 'warm_start_init_step': 0}
[[11/15/2018 06:05:38 PM]] all parameters:
[[11/15/2018 06:05:38 PM]] [('word_embeddings:0', [24475, 300]),
 ('char_embeddings:0', [77, 100]),
 ('bidirectional_rnn/fw/lstm_cell/kernel:0', [200, 400]),
 ('bidirectional_rnn/fw/lstm_cell/bias:0', [400]),
 ('bidirectional_rnn/bw/lstm_cell/kernel:0', [200, 400]),
 ('bidirectional_rnn/bw/lstm_cell/bias:0', [400]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/weights:0', [3, 500, 300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/g:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/biases:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/weights:0', [3, 300, 300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/g:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/biases:0', [300]),
 ('word_level/W_h-in-block-1:0', [1, 500, 300]),
 ('word_level/b_h-in-block-1:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/weights:0', [3, 300, 250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/g:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/biases:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/weights:0', [3, 250, 250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/g:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/biases:0', [250]),
 ('word_level/W_h-in-block-2:0', [1, 300, 250]),
 ('word_level/b_h-in-block-2:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/weights:0', [3, 250, 200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/g:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/biases:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/weights:0', [3, 200, 200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/g:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/biases:0', [200]),
 ('word_level/W_h-in-block-3:0', [1, 250, 200]),
 ('word_level/b_h-in-block-3:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/weights:0', [3, 200, 150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/g:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/biases:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/weights:0', [3, 150, 150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/g:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/biases:0', [150]),
 ('word_level/W_h-in-block-4:0', [1, 200, 150]),
 ('word_level/b_h-in-block-4:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/weights:0', [3, 150, 100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/g:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/biases:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/weights:0', [3, 100, 100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/g:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/biases:0', [100]),
 ('word_level/W_h-in-block-5:0', [1, 150, 100]),
 ('word_level/b_h-in-block-5:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/weights:0', [3, 100, 50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/g:0', [50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/biases:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/weights:0', [3, 50, 50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/g:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/biases:0', [50]),
 ('word_level/W_h-in-block-6:0', [1, 100, 50]),
 ('word_level/b_h-in-block-6:0', [50]),
 ('output-layer/weights:0', [50, 3]),
 ('output-layer/biases:0', [3]),
 ('Variable:0', []),
 ('Variable_1:0', []),
 ('beta1_power:0', []),
 ('beta2_power:0', []),
 ('char_embeddings/Adam:0', [77, 100]),
 ('char_embeddings/Adam_1:0', [77, 100]),
 ('bidirectional_rnn/fw/lstm_cell/kernel/Adam:0', [200, 400]),
 ('bidirectional_rnn/fw/lstm_cell/kernel/Adam_1:0', [200, 400]),
 ('bidirectional_rnn/fw/lstm_cell/bias/Adam:0', [400]),
 ('bidirectional_rnn/fw/lstm_cell/bias/Adam_1:0', [400]),
 ('bidirectional_rnn/bw/lstm_cell/kernel/Adam:0', [200, 400]),
 ('bidirectional_rnn/bw/lstm_cell/kernel/Adam_1:0', [200, 400]),
 ('bidirectional_rnn/bw/lstm_cell/bias/Adam:0', [400]),
 ('bidirectional_rnn/bw/lstm_cell/bias/Adam_1:0', [400]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/weights/Adam:0', [3, 500, 300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/weights/Adam_1:0',
  [3, 500, 300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/g/Adam:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/g/Adam_1:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/biases/Adam:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/biases/Adam_1:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/weights/Adam:0', [3, 300, 300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/weights/Adam_1:0',
  [3, 300, 300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/g/Adam:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/g/Adam_1:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/biases/Adam:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/biases/Adam_1:0', [300]),
 ('word_level/W_h-in-block-1/Adam:0', [1, 500, 300]),
 ('word_level/W_h-in-block-1/Adam_1:0', [1, 500, 300]),
 ('word_level/b_h-in-block-1/Adam:0', [300]),
 ('word_level/b_h-in-block-1/Adam_1:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/weights/Adam:0', [3, 300, 250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/weights/Adam_1:0',
  [3, 300, 250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/g/Adam:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/g/Adam_1:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/biases/Adam:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/biases/Adam_1:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/weights/Adam:0', [3, 250, 250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/weights/Adam_1:0',
  [3, 250, 250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/g/Adam:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/g/Adam_1:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/biases/Adam:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/biases/Adam_1:0', [250]),
 ('word_level/W_h-in-block-2/Adam:0', [1, 300, 250]),
 ('word_level/W_h-in-block-2/Adam_1:0', [1, 300, 250]),
 ('word_level/b_h-in-block-2/Adam:0', [250]),
 ('word_level/b_h-in-block-2/Adam_1:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/weights/Adam:0', [3, 250, 200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/weights/Adam_1:0',
  [3, 250, 200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/g/Adam:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/g/Adam_1:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/biases/Adam:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/biases/Adam_1:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/weights/Adam:0', [3, 200, 200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/weights/Adam_1:0',
  [3, 200, 200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/g/Adam:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/g/Adam_1:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/biases/Adam:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/biases/Adam_1:0', [200]),
 ('word_level/W_h-in-block-3/Adam:0', [1, 250, 200]),
 ('word_level/W_h-in-block-3/Adam_1:0', [1, 250, 200]),
 ('word_level/b_h-in-block-3/Adam:0', [200]),
 ('word_level/b_h-in-block-3/Adam_1:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/weights/Adam:0', [3, 200, 150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/weights/Adam_1:0',
  [3, 200, 150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/g/Adam:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/g/Adam_1:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/biases/Adam:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/biases/Adam_1:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/weights/Adam:0', [3, 150, 150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/weights/Adam_1:0',
  [3, 150, 150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/g/Adam:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/g/Adam_1:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/biases/Adam:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/biases/Adam_1:0', [150]),
 ('word_level/W_h-in-block-4/Adam:0', [1, 200, 150]),
 ('word_level/W_h-in-block-4/Adam_1:0', [1, 200, 150]),
 ('word_level/b_h-in-block-4/Adam:0', [150]),
 ('word_level/b_h-in-block-4/Adam_1:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/weights/Adam:0', [3, 150, 100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/weights/Adam_1:0',
  [3, 150, 100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/g/Adam:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/g/Adam_1:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/biases/Adam:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/biases/Adam_1:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/weights/Adam:0', [3, 100, 100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/weights/Adam_1:0',
  [3, 100, 100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/g/Adam:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/g/Adam_1:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/biases/Adam:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/biases/Adam_1:0', [100]),
 ('word_level/W_h-in-block-5/Adam:0', [1, 150, 100]),
 ('word_level/W_h-in-block-5/Adam_1:0', [1, 150, 100]),
 ('word_level/b_h-in-block-5/Adam:0', [100]),
 ('word_level/b_h-in-block-5/Adam_1:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/weights/Adam:0', [3, 100, 50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/weights/Adam_1:0',
  [3, 100, 50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/g/Adam:0', [50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/g/Adam_1:0', [50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/biases/Adam:0', [50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/biases/Adam_1:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/weights/Adam:0', [3, 50, 50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/weights/Adam_1:0', [3, 50, 50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/g/Adam:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/g/Adam_1:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/biases/Adam:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/biases/Adam_1:0', [50]),
 ('word_level/W_h-in-block-6/Adam:0', [1, 100, 50]),
 ('word_level/W_h-in-block-6/Adam_1:0', [1, 100, 50]),
 ('word_level/b_h-in-block-6/Adam:0', [50]),
 ('word_level/b_h-in-block-6/Adam_1:0', [50]),
 ('output-layer/weights/Adam:0', [50, 3]),
 ('output-layer/weights/Adam_1:0', [50, 3]),
 ('output-layer/biases/Adam:0', [3]),
 ('output-layer/biases/Adam_1:0', [3])]
[[11/15/2018 06:05:38 PM]] trainable parameters:
[[11/15/2018 06:05:38 PM]] [('char_embeddings:0', [77, 100]),
 ('bidirectional_rnn/fw/lstm_cell/kernel:0', [200, 400]),
 ('bidirectional_rnn/fw/lstm_cell/bias:0', [400]),
 ('bidirectional_rnn/bw/lstm_cell/kernel:0', [200, 400]),
 ('bidirectional_rnn/bw/lstm_cell/bias:0', [400]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/weights:0', [3, 500, 300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/g:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/biases:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/weights:0', [3, 300, 300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/g:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/biases:0', [300]),
 ('word_level/W_h-in-block-1:0', [1, 500, 300]),
 ('word_level/b_h-in-block-1:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/weights:0', [3, 300, 250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/g:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/biases:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/weights:0', [3, 250, 250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/g:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/biases:0', [250]),
 ('word_level/W_h-in-block-2:0', [1, 300, 250]),
 ('word_level/b_h-in-block-2:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/weights:0', [3, 250, 200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/g:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/biases:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/weights:0', [3, 200, 200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/g:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/biases:0', [200]),
 ('word_level/W_h-in-block-3:0', [1, 250, 200]),
 ('word_level/b_h-in-block-3:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/weights:0', [3, 200, 150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/g:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/biases:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/weights:0', [3, 150, 150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/g:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/biases:0', [150]),
 ('word_level/W_h-in-block-4:0', [1, 200, 150]),
 ('word_level/b_h-in-block-4:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/weights:0', [3, 150, 100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/g:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/biases:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/weights:0', [3, 100, 100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/g:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/biases:0', [100]),
 ('word_level/W_h-in-block-5:0', [1, 150, 100]),
 ('word_level/b_h-in-block-5:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/weights:0', [3, 100, 50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/g:0', [50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/biases:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/weights:0', [3, 50, 50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/g:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/biases:0', [50]),
 ('word_level/W_h-in-block-6:0', [1, 100, 50]),
 ('word_level/b_h-in-block-6:0', [50]),
 ('output-layer/weights:0', [50, 3]),
 ('output-layer/biases:0', [3])]
[[11/15/2018 06:05:38 PM]] trainable parameter count:
[[11/15/2018 06:05:38 PM]] 2156403
[[11/15/2018 06:05:46 PM]] [[step        0]]     [[train]]     loss: 1.16964161       [[val]]     score: 0.0              
[[11/15/2018 06:05:47 PM]] [[step        1]]     [[train]]     loss: 0.93335745       [[val]]     score: 0.0              
[[11/15/2018 06:05:48 PM]] [[step        2]]     [[train]]     loss: 0.90186763       [[val]]     score: 0.0              
[[11/15/2018 06:05:49 PM]] [[step        3]]     [[train]]     loss: 0.76332559       [[val]]     score: 0.0              
[[11/15/2018 06:05:51 PM]] [[step        4]]     [[train]]     loss: 0.74242891       [[val]]     score: 0.0              
[[11/15/2018 06:05:52 PM]] [[step        5]]     [[train]]     loss: 0.6695688        [[val]]     score: 0.0              
[[11/15/2018 06:05:53 PM]] [[step        6]]     [[train]]     loss: 0.62603425       [[val]]     score: 0.0              
[[11/15/2018 06:05:54 PM]] [[step        7]]     [[train]]     loss: 0.58699336       [[val]]     score: 0.0              
[[11/15/2018 06:05:56 PM]] [[step        8]]     [[train]]     loss: 0.5538697        [[val]]     score: 0.0              
[[11/15/2018 06:05:57 PM]] [[step        9]]     [[train]]     loss: 0.5248223        [[val]]     score: 0.0              
[[11/15/2018 06:05:58 PM]] [[step       10]]     [[train]]     loss: 0.49816006       [[val]]     score: 0.0              
[[11/15/2018 06:06:00 PM]] [[step       11]]     [[train]]     loss: 0.47357084       [[val]]     score: 0.02795839       
[[11/15/2018 06:06:01 PM]] [[step       12]]     [[train]]     loss: 0.45271832       [[val]]     score: 0.07180993       
