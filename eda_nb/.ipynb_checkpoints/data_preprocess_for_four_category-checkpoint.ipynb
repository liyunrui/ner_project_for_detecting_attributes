{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\"\"\"\n",
    "Created on Oct 24 2018\n",
    "\n",
    "Text preprocessing and sequential labeling.\n",
    "\n",
    "TO do list in the future:\n",
    "    - pull data again using pyspark for getting original item_name when need feature engineering.\n",
    "\n",
    "@author: Ray\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import ast # real json-like string\n",
    "import pandas as pd\n",
    "import gc\n",
    "sys.path.append('../../brand_recognition_bio_FE/preprocessing')\n",
    "from clean_helpers import clean_name\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "\n",
    "def filter_data_for_ner_task(df, out_col, FLAG, attr = ' Brand'):\n",
    "    \"\"\"\n",
    "    Return reliable data that we generally make sure attribute you assigned exist in the title.\n",
    "    \"\"\"\n",
    "    num_filter = 0\n",
    "    keep = []\n",
    "    attr_tags = []\n",
    "    sku_need_to_replenish_attribute = []\n",
    "    for ix, row in df.iterrows():\n",
    "        if FLAG == 'shopee':\n",
    "            title = row['title'] # str\n",
    "            #tagging_dict = ast.literal_eval(row['mobile']) # dict \n",
    "            tagging_dict = ast.literal_eval(row[9]) \n",
    "            #--------------\n",
    "            # preprocessing for tagging filed in raw shaopee data\n",
    "            #--------------\n",
    "            try:\n",
    "                if tagging_dict[attr] != 'no value':\n",
    "                    attr_tag = tagging_dict[attr][0][0] # str\n",
    "                else:\n",
    "                    attr_tag = tagging_dict[attr] # str\n",
    "            except:\n",
    "                try:\n",
    "                    attr1 = 'Brand'\n",
    "                    if tagging_dict[attr1] != 'no value':\n",
    "                        attr_tag = tagging_dict[attr1][0][0] # str\n",
    "                    else:\n",
    "                        attr_tag = tagging_dict[attr1] # str\n",
    "                except:\n",
    "                    attr2 = ' brand'\n",
    "                    if tagging_dict[attr2] != 'no value':\n",
    "                        attr_tag = tagging_dict[attr2][0][0] # str\n",
    "                    else:\n",
    "                        attr_tag = tagging_dict[attr2] # str\n",
    "                   \n",
    "            #--------------\n",
    "            # core\n",
    "            #--------------\n",
    "            if attr_tag == 'no value':\n",
    "                num_filter += 1\n",
    "                keep.append(0)\n",
    "                attr_tags.append(0)\n",
    "                sku_need_to_replenish_attribute.append(title)\n",
    "            elif attr_tag.lower() in title.lower():\n",
    "                keep.append(1)\n",
    "                attr_tags.append(attr_tag)\n",
    "            else:\n",
    "                num_filter += 1\n",
    "                keep.append(0)\n",
    "                attr_tags.append(0)\n",
    "        elif FLAG == 'lazada':\n",
    "            title = row['item_name'] # str\n",
    "            attr_tag = row['brand'] # str\n",
    "            if attr_tag.lower() in title.lower():\n",
    "                keep.append(1)\n",
    "                attr_tags.append(attr_tag)\n",
    "            else:\n",
    "                num_filter += 1\n",
    "                keep.append(0)\n",
    "                attr_tags.append(0)\n",
    "            \n",
    "        else:\n",
    "            # if the assertion fails, Python uses ArgumentExpression as the argument for the AssertionError. \n",
    "            assert False,  '========= the FLAG only accecpt shopee and lazada lah fuck u =========' # condition, AssertionError\n",
    "    # save sku without attribute value\n",
    "    df[df.title.isin(sku_need_to_replenish_attribute)].to_csv('../data/processed/{}_missing.csv'.format(category), index = False)\n",
    "\n",
    "    #-----------------\n",
    "    # output\n",
    "    #-----------------\n",
    "    df['keep'] = keep\n",
    "    df['attr_tags'] = attr_tags\n",
    "\n",
    "    if FLAG == 'shopee':\n",
    "        pass\n",
    "    elif FLAG == 'lazada':\n",
    "        df.drop(['brand'], axis = 1, inplace = True)\n",
    "    else:\n",
    "        assert False, '========= the FLAG only accecpt shopee and lazada lah fuck u ========='\n",
    "\n",
    "    df.rename(columns = {'title': out_col[0], 'attr_tags':out_col[1]}, inplace = True)\n",
    "    df = df[df.keep == 1]\n",
    "    df = df[out_col]\n",
    "    gc.collect()\n",
    "    return df, num_filter, sku_need_to_replenish_attribute\n",
    "\n",
    "def sequence_labeling_w_bio_encoding(row, NORMALIZED = False):\n",
    "    '''\n",
    "    BIO encoding is a distant supervision approach to automatically generate training data for training machine-learning based model. \n",
    "    \n",
    "        # B-B: 2\n",
    "        # I-B: 1\n",
    "        # O: 0\n",
    "    Reference for distant supervision approach: http://deepdive.stanford.edu/distant_supervision\n",
    "    Reference for BIO : Attribute Extraction from Product Titles in eCommerce.\n",
    "   \n",
    "    parameters:\n",
    "    --------------\n",
    "    df: DataFrame\n",
    "    if_assumption: str. if True, we assume we only have one-single brand_word in one item_name. \n",
    "    Otherwise, we can have multiple token with positive lable in one item_name.\n",
    "    '''\n",
    "\n",
    "    # initialize variables\n",
    "    word_list = []\n",
    "    tagging = [] # multi-class label, {0:not part of the brand name, 1: intermediate part of the brand name, 2:beginning of the brand name}\n",
    "    item_name = []\n",
    "    val = [] \n",
    "    #---------------\n",
    "    # sequential labeling with BIO encoding\n",
    "    #---------------\n",
    "    brand_started = False\n",
    "    b_ix = 0\n",
    "    brand = row.what_brand_name.iloc[0].split(' ')\n",
    "    title = clean_name(row['item_name'].iloc[0]).split(' ')\n",
    "    # filter\n",
    "    title = [t for t in title if '' != t]\n",
    "    for w_ix, word in enumerate(title):\n",
    "        if word.lower() == brand[0].lower():\n",
    "            tagging.append(2) # B-B: 2\n",
    "            brand_started = True\n",
    "            b_ix += 1\n",
    "        elif (len(brand) > 1) and (brand_started):\n",
    "            if b_ix >= len(brand):\n",
    "                # for avoiding . For example, if 'BUMBLE AND BUMBLE by Bumble and Bumble: QUENCHING CONDITIONER 8.5 OZ'\n",
    "                tagging.append(0) # O: 0\n",
    "                brand_started = False  \n",
    "                b_ix = 0                \n",
    "            else:\n",
    "                if word.lower() == brand[b_ix].lower():\n",
    "                    tagging.append(1) # I-B: 1\n",
    "                    b_ix += 1\n",
    "                    if b_ix == len(brand):\n",
    "                        # go back to orginal state because we already marked what we want\n",
    "                        brand_started = False\n",
    "                        b_ix = 0\n",
    "                else:\n",
    "                    tagging.append(0) # O: 0\n",
    "                    brand_started = False     \n",
    "                    # if we need to modified the labeling we priviously marked.\n",
    "                    if b_ix < len(brand):\n",
    "                        go_back_to_modified = 0\n",
    "                        for i in range(b_ix):\n",
    "                            #print ('w_ix', w_ix) # w_ix 對應的不是整個 tagging的list: 兩個解法, 1.groupby 2.w_ix要一直被加上\n",
    "                            go_back_to_modified += 1\n",
    "                            #print ('go back', w_ix - go_back_to_modified)\n",
    "                            tagging[w_ix - go_back_to_modified] = 0 # O: 0\n",
    "                        # Once removing privous labeling, we update b_ix to zero\n",
    "                        b_ix = 0         \n",
    "        else:\n",
    "            brand_started = False\n",
    "            tagging.append(0) # O: 0\n",
    "        #---------------------------\n",
    "        # for output dataframe\n",
    "        #---------------------------\n",
    "        if NORMALIZED == True:\n",
    "            word_list.append(word.lower())\n",
    "        else:\n",
    "            word_list.append(word)\n",
    "        item_name.append(clean_name(row['item_name'].iloc[0]))\n",
    "        val.append(row['eval_set'].iloc[0])\n",
    "    #---------------------------\n",
    "    # output\n",
    "    #---------------------------\n",
    "    df = pd.DataFrame({'tokens':word_list, \n",
    "                'label': tagging,\n",
    "                'eval_set': val,\n",
    "                'item_name':item_name})[['item_name','tokens','label','eval_set']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beauty-Lips\n",
    "# Beauty-face\n",
    "# Women top\n",
    "# Women dress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lips', 'dress', 'face', 'women_top', 'mobile']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/data/ner_task/dress/shopee_data_tagging_result/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shopee = pd.read_csv('/data/ner_task/dress/shopee_data_tagging_result/dress/dress_ID_attribute_tagging_v2.csv')\n",
    "# shopee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ix, row in shoope_mobile.sample(100).iterrows():\n",
    "#     print (row[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lips', 'dress', 'face', 'women_top', 'mobile']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/data/ner_task/dress/shopee_data_tagging_result/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category : lips\n",
      "# training sku : 112415\n",
      "# testing sku : 28104\n",
      "eval_set-distribution train    35291\n",
      "test      8857\n",
      "Name: eval_set, dtype: int64\n",
      "number of validating sku : 3529\n",
      "num_sku_removed from shopee: 62685\n",
      "# of total sku : 44148\n",
      "# training sku : 31762\n",
      "# validating sku : 3529\n",
      "# testing sku : 8857\n",
      "testing ration : 0.20062063966657606\n",
      "category : dress\n",
      "# training sku : 302864\n",
      "# testing sku : 75716\n",
      "eval_set-distribution train    3498\n",
      "test      492\n",
      "Name: eval_set, dtype: int64\n",
      "number of validating sku : 349\n",
      "num_sku_removed from shopee: 332061\n",
      "# of total sku : 3990\n",
      "# training sku : 3149\n",
      "# validating sku : 349\n",
      "# testing sku : 492\n",
      "testing ration : 0.12330827067669173\n",
      "category : face\n",
      "# training sku : 211920\n",
      "# testing sku : 52990\n",
      "eval_set-distribution train    58844\n",
      "test     15121\n",
      "Name: eval_set, dtype: int64\n",
      "number of validating sku : 5884\n",
      "num_sku_removed from shopee: 138161\n",
      "# of total sku : 73965\n",
      "# training sku : 52960\n",
      "# validating sku : 5884\n",
      "# testing sku : 15121\n",
      "testing ration : 0.20443452984519705\n",
      "category : women_top\n",
      "# training sku : 304304\n",
      "# testing sku : 76080\n",
      "eval_set-distribution train    6789\n",
      "test     1391\n",
      "Name: eval_set, dtype: int64\n",
      "number of validating sku : 678\n",
      "num_sku_removed from shopee: 339057\n",
      "# of total sku : 8180\n",
      "# training sku : 6111\n",
      "# validating sku : 678\n",
      "# testing sku : 1391\n",
      "testing ration : 0.17004889975550122\n",
      "category : mobile\n",
      "# training sku : 247831\n",
      "# testing sku : 61958\n",
      "eval_set-distribution train    160247\n",
      "test      26642\n",
      "Name: eval_set, dtype: int64\n",
      "number of validating sku : 16024\n",
      "num_sku_removed from shopee: 43667\n",
      "# of total sku : 186889\n",
      "# training sku : 144223\n",
      "# validating sku : 16024\n",
      "# testing sku : 26642\n",
      "testing ration : 0.1425552065664646\n"
     ]
    }
   ],
   "source": [
    "for category in os.listdir('/data/ner_task/dress/shopee_data_tagging_result/')[:]:\n",
    "    #--------------------------\n",
    "    # setting\n",
    "    #--------------------------\n",
    "    print ('category : {}'.format(category))\n",
    "    file_name = [i for i in os.listdir('/data/ner_task/dress/shopee_data_tagging_result/{}'.format(category)) if 'v2' in i ][0]\n",
    "    date_path = '/data/ner_task/dress/shopee_data_tagging_result/{}/{}'.format(category, file_name)\n",
    "    # output column\n",
    "    output_column = ['item_name', 'brand', 'eval_set']\n",
    "    # train/val ratio\n",
    "    val_size = 0.1\n",
    "    #--------------------------\n",
    "    # loading data\n",
    "    #--------------------------\n",
    "    shopee = pd.read_csv(date_path)\n",
    "    print ('# training sku : {}'.format(len(shopee[shopee.eval_set == 'train'])))\n",
    "    print ('# testing sku : {}'.format(len(shopee[shopee.eval_set == 'test'])))\n",
    "\n",
    "    #--------------------------\n",
    "    # preprocessing data\n",
    "    #--------------------------\n",
    "    # droup duplicated: make our result trustworthy, don't count the same itemname with same brand \n",
    "    shopee.drop_duplicates(subset = ['title'], inplace = True)\n",
    "    shopee = shopee.reset_index(drop = True)\n",
    "    #--------------------------\n",
    "    # filter: In order to get high-quality data, we remove the sku that his attribute name do not exist in title from our shopee data.\n",
    "    #--------------------------\n",
    "    attr = ' Brand'\n",
    "    shopee, num_filter_s, sku_need_to_replenish_attribute = filter_data_for_ner_task(shopee, FLAG = 'shopee', out_col = output_column, attr =  attr)\n",
    "    shopee.reset_index(drop = True, inplace = True)\n",
    "    print ('eval_set-distribution', shopee.eval_set.value_counts())\n",
    "    #--------------------------\n",
    "    # data configuration\n",
    "    #-------------------------- \n",
    "    # using time-series split method as validating strategy: switch to shuffle with item_id\n",
    "    n = int(len(shopee[shopee.eval_set == 'train']) * val_size)\n",
    "    print ('number of validating sku : {}'.format(n))\n",
    "    val_item_name = set(pd.Series(shopee[shopee.eval_set == 'train'].tail(n).item_name))\n",
    "    for ix, row in shopee[shopee.eval_set == 'train'].iterrows():\n",
    "        if row['item_name'] in val_item_name:\n",
    "            shopee['eval_set'].iloc[ix] = 'val' \n",
    "\n",
    "    print ('num_sku_removed from shopee: {}'.format(num_filter_s))\n",
    "    print ('# of total sku : {}'.format(len(shopee)))\n",
    "    print ('# training sku : {}'.format(len(shopee[shopee.eval_set == 'train'])))\n",
    "    print ('# validating sku : {}'.format(len(shopee[shopee.eval_set == 'val'])))\n",
    "    print ('# testing sku : {}'.format(len(shopee[shopee.eval_set == 'test'])))\n",
    "    print ('testing ration : {}'.format(len(shopee[shopee.eval_set == 'test']) / len(shopee)))\n",
    "    df = pd.concat([\n",
    "        #lazada_mobile[output_column], \n",
    "        shopee[output_column]\n",
    "    ], axis = 0)\n",
    "    #del shopee\n",
    "    gc.collect()\n",
    "    #--------------------------\n",
    "    # BIO tagging\n",
    "    #--------------------------\n",
    "    df.rename(columns = {'brand':'what_brand_name'}, inplace = True)\n",
    "\n",
    "    df = df.groupby('item_name').apply(lambda x: sequence_labeling_w_bio_encoding(x, NORMALIZED = False)).reset_index(drop = True)\n",
    "\n",
    "    #-------------------------\n",
    "    # post-processing: remove some sku we cannot tag trough our sequential labeling.\n",
    "    #-------------------------\n",
    "    '''\n",
    "    It's very little and the reason why this happening after text processomg is, for example, let's say a title of sku and brand is buy 1 get 1 free kasus and asus\n",
    "    Then, he won't be filtered by text processing.\n",
    "    '''\n",
    "    no_label_item_name = df.groupby('item_name').label.mean().to_frame().reset_index()\n",
    "    no_label_item_name = no_label_item_name[no_label_item_name.label == 0].item_name.tolist()\n",
    "    df = df[~df.item_name.isin(no_label_item_name)]\n",
    "\n",
    "    gc.collect()\n",
    "    #--------------------------\n",
    "    # save\n",
    "    #--------------------------\n",
    "    base_path = '../data/processed'\n",
    "\n",
    "    if not os.path.isdir(base_path):\n",
    "        os.makedirs(base_path)\n",
    "\n",
    "    df.to_csv(os.path.join(base_path,'{}_training.csv'.format(category)) , index = False)\n",
    "    print ('sucessfully saving the {} data'.format(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-788ee363e0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8857/44148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_need_to_replenish_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shopee.eval_set.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "drop by itemid:\n",
    "lips\n",
    "num_sku_removed from shopee: 509\n",
    "# of total sku : 491\n",
    "# training sku : 416\n",
    "# validating sku : 75\n",
    "# testing sku : 0\n",
    "category : dress\n",
    "number of validating sku : 100\n",
    "num_sku_removed from shopee: 997\n",
    "# of total sku : 3\n",
    "# training sku : 3\n",
    "# validating sku : 0\n",
    "# testing sku : 0\n",
    "category : face\n",
    "number of validating sku : 100\n",
    "num_sku_removed from shopee: 618\n",
    "# of total sku : 382\n",
    "# training sku : 333\n",
    "# validating sku : 49\n",
    "# testing sku : 0\n",
    "category : women_top\n",
    "number of validating sku : 100\n",
    "num_sku_removed from shopee: 988\n",
    "# of total sku : 12\n",
    "# training sku : 10\n",
    "# validating sku : 2\n",
    "# testing sku : 0\n",
    "category : mobile\n",
    "number of validating sku : 100\n",
    "num_sku_removed from shopee: 279\n",
    "# of total sku : 721\n",
    "# training sku : 643\n",
    "# validating sku : 78\n",
    "# testing sku : 0\n",
    "\n",
    "drop by itemname:\n",
    "lips\n",
    "num_sku_removed from shopee: 470\n",
    "# of total sku : 439\n",
    "# training sku : 394\n",
    "# validating sku : 45\n",
    "# testing sku : 0\n",
    "category : dress\n",
    "number of validating sku : 98\n",
    "num_sku_removed from shopee: 982\n",
    "# of total sku : 3\n",
    "# training sku : 3\n",
    "# validating sku : 0\n",
    "# testing sku : 0\n",
    "category : face\n",
    "number of validating sku : 95\n",
    "num_sku_removed from shopee: 604\n",
    "# of total sku : 355\n",
    "# training sku : 317\n",
    "# validating sku : 38\n",
    "# testing sku : 0\n",
    "category : women_top\n",
    "number of validating sku : 97\n",
    "num_sku_removed from shopee: 967\n",
    "# of total sku : 12\n",
    "# training sku : 10\n",
    "# validating sku : 2\n",
    "# testing sku : 0\n",
    "category : mobile\n",
    "number of validating sku : 98\n",
    "num_sku_removed from shopee: 275\n",
    "# of total sku : 713\n",
    "# training sku : 638\n",
    "# validating sku : 75\n",
    "# testing sku : 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopee.drop_duplicates('item_name').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopee.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/data/ner_task/data_for_brand_detection_model/face_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'women_top_training.csv'[:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
