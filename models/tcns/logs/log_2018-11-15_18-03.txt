[[11/15/2018 06:03:05 PM]] 
new run with parameters:
{'USE_CHARS': True,
 'batch_size': 128,
 'causal': False,
 'char_representation_method': 'CNN',
 'checkpoint_dir': 'checkpoints_wo_causal_cnn_char',
 'dim_char': 100,
 'dim_word': 300,
 'early_stopping_steps': 3000,
 'enable_parameter_averaging': False,
 'filter_widths': 3,
 'filter_widths_char': 5,
 'grad_clip': 5,
 'hidden_size_char': 100,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.001,
 'log_dir': 'logs',
 'log_interval': 1,
 'loss_averaging_window': 100,
 'max_seq_len': 36,
 'max_word_length': 54,
 'metric': 'f1',
 'min_steps_to_checkpoint': 500,
 'nchars': 77,
 'ntags': 3,
 'num_channels': [300, 250, 200, 150, 100, 50],
 'num_channels_char': [200, 200],
 'num_restarts': 0,
 'num_training_steps': 15000,
 'num_validation_batches': 10,
 'nwords': 24475,
 'optimizer': 'adam',
 'prediction_dir': 'predictions_wo_causal_cnn_char',
 'reader': <__main__.DataReader object at 0x7f099ce00470>,
 'regularization_constant': 0.0,
 'trainable_embedding': False,
 'use_evaluation_metric_as_early_stopping': True,
 'warm_start_init_step': 0}
[[11/15/2018 06:03:08 PM]] all parameters:
[[11/15/2018 06:03:08 PM]] [('word_embeddings:0', [24475, 300]),
 ('char_embeddings:0', [77, 100]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/weights:0', [5, 100, 200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/g:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/biases:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/weights:0', [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/g:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/biases:0', [200]),
 ('char_level/W_h-in-block-1:0', [1, 100, 200]),
 ('char_level/b_h-in-block-1:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/weights:0', [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/g:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/biases:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/weights:0', [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/g:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/biases:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/weights:0', [3, 500, 300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/g:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/biases:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/weights:0', [3, 300, 300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/g:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/biases:0', [300]),
 ('word_level/W_h-in-block-1:0', [1, 500, 300]),
 ('word_level/b_h-in-block-1:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/weights:0', [3, 300, 250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/g:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/biases:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/weights:0', [3, 250, 250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/g:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/biases:0', [250]),
 ('word_level/W_h-in-block-2:0', [1, 300, 250]),
 ('word_level/b_h-in-block-2:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/weights:0', [3, 250, 200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/g:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/biases:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/weights:0', [3, 200, 200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/g:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/biases:0', [200]),
 ('word_level/W_h-in-block-3:0', [1, 250, 200]),
 ('word_level/b_h-in-block-3:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/weights:0', [3, 200, 150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/g:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/biases:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/weights:0', [3, 150, 150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/g:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/biases:0', [150]),
 ('word_level/W_h-in-block-4:0', [1, 200, 150]),
 ('word_level/b_h-in-block-4:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/weights:0', [3, 150, 100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/g:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/biases:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/weights:0', [3, 100, 100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/g:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/biases:0', [100]),
 ('word_level/W_h-in-block-5:0', [1, 150, 100]),
 ('word_level/b_h-in-block-5:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/weights:0', [3, 100, 50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/g:0', [50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/biases:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/weights:0', [3, 50, 50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/g:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/biases:0', [50]),
 ('word_level/W_h-in-block-6:0', [1, 100, 50]),
 ('word_level/b_h-in-block-6:0', [50]),
 ('output-layer/weights:0', [50, 3]),
 ('output-layer/biases:0', [3]),
 ('Variable:0', []),
 ('Variable_1:0', []),
 ('beta1_power:0', []),
 ('beta2_power:0', []),
 ('char_embeddings/Adam:0', [77, 100]),
 ('char_embeddings/Adam_1:0', [77, 100]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/weights/Adam:0', [5, 100, 200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/weights/Adam_1:0',
  [5, 100, 200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/g/Adam:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/g/Adam_1:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/biases/Adam:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/biases/Adam_1:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/weights/Adam:0', [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/weights/Adam_1:0',
  [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/g/Adam:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/g/Adam_1:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/biases/Adam:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/biases/Adam_1:0', [200]),
 ('char_level/W_h-in-block-1/Adam:0', [1, 100, 200]),
 ('char_level/W_h-in-block-1/Adam_1:0', [1, 100, 200]),
 ('char_level/b_h-in-block-1/Adam:0', [200]),
 ('char_level/b_h-in-block-1/Adam_1:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/weights/Adam:0', [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/weights/Adam_1:0',
  [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/g/Adam:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/g/Adam_1:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/biases/Adam:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/biases/Adam_1:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/weights/Adam:0', [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/weights/Adam_1:0',
  [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/g/Adam:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/g/Adam_1:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/biases/Adam:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/biases/Adam_1:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/weights/Adam:0', [3, 500, 300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/weights/Adam_1:0',
  [3, 500, 300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/g/Adam:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/g/Adam_1:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/biases/Adam:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/biases/Adam_1:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/weights/Adam:0', [3, 300, 300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/weights/Adam_1:0',
  [3, 300, 300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/g/Adam:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/g/Adam_1:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/biases/Adam:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/biases/Adam_1:0', [300]),
 ('word_level/W_h-in-block-1/Adam:0', [1, 500, 300]),
 ('word_level/W_h-in-block-1/Adam_1:0', [1, 500, 300]),
 ('word_level/b_h-in-block-1/Adam:0', [300]),
 ('word_level/b_h-in-block-1/Adam_1:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/weights/Adam:0', [3, 300, 250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/weights/Adam_1:0',
  [3, 300, 250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/g/Adam:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/g/Adam_1:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/biases/Adam:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/biases/Adam_1:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/weights/Adam:0', [3, 250, 250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/weights/Adam_1:0',
  [3, 250, 250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/g/Adam:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/g/Adam_1:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/biases/Adam:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/biases/Adam_1:0', [250]),
 ('word_level/W_h-in-block-2/Adam:0', [1, 300, 250]),
 ('word_level/W_h-in-block-2/Adam_1:0', [1, 300, 250]),
 ('word_level/b_h-in-block-2/Adam:0', [250]),
 ('word_level/b_h-in-block-2/Adam_1:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/weights/Adam:0', [3, 250, 200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/weights/Adam_1:0',
  [3, 250, 200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/g/Adam:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/g/Adam_1:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/biases/Adam:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/biases/Adam_1:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/weights/Adam:0', [3, 200, 200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/weights/Adam_1:0',
  [3, 200, 200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/g/Adam:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/g/Adam_1:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/biases/Adam:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/biases/Adam_1:0', [200]),
 ('word_level/W_h-in-block-3/Adam:0', [1, 250, 200]),
 ('word_level/W_h-in-block-3/Adam_1:0', [1, 250, 200]),
 ('word_level/b_h-in-block-3/Adam:0', [200]),
 ('word_level/b_h-in-block-3/Adam_1:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/weights/Adam:0', [3, 200, 150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/weights/Adam_1:0',
  [3, 200, 150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/g/Adam:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/g/Adam_1:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/biases/Adam:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/biases/Adam_1:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/weights/Adam:0', [3, 150, 150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/weights/Adam_1:0',
  [3, 150, 150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/g/Adam:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/g/Adam_1:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/biases/Adam:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/biases/Adam_1:0', [150]),
 ('word_level/W_h-in-block-4/Adam:0', [1, 200, 150]),
 ('word_level/W_h-in-block-4/Adam_1:0', [1, 200, 150]),
 ('word_level/b_h-in-block-4/Adam:0', [150]),
 ('word_level/b_h-in-block-4/Adam_1:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/weights/Adam:0', [3, 150, 100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/weights/Adam_1:0',
  [3, 150, 100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/g/Adam:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/g/Adam_1:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/biases/Adam:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/biases/Adam_1:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/weights/Adam:0', [3, 100, 100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/weights/Adam_1:0',
  [3, 100, 100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/g/Adam:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/g/Adam_1:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/biases/Adam:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/biases/Adam_1:0', [100]),
 ('word_level/W_h-in-block-5/Adam:0', [1, 150, 100]),
 ('word_level/W_h-in-block-5/Adam_1:0', [1, 150, 100]),
 ('word_level/b_h-in-block-5/Adam:0', [100]),
 ('word_level/b_h-in-block-5/Adam_1:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/weights/Adam:0', [3, 100, 50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/weights/Adam_1:0',
  [3, 100, 50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/g/Adam:0', [50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/g/Adam_1:0', [50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/biases/Adam:0', [50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/biases/Adam_1:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/weights/Adam:0', [3, 50, 50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/weights/Adam_1:0', [3, 50, 50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/g/Adam:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/g/Adam_1:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/biases/Adam:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/biases/Adam_1:0', [50]),
 ('word_level/W_h-in-block-6/Adam:0', [1, 100, 50]),
 ('word_level/W_h-in-block-6/Adam_1:0', [1, 100, 50]),
 ('word_level/b_h-in-block-6/Adam:0', [50]),
 ('word_level/b_h-in-block-6/Adam_1:0', [50]),
 ('output-layer/weights/Adam:0', [50, 3]),
 ('output-layer/weights/Adam_1:0', [50, 3]),
 ('output-layer/biases/Adam:0', [3]),
 ('output-layer/biases/Adam_1:0', [3])]
[[11/15/2018 06:03:08 PM]] trainable parameters:
[[11/15/2018 06:03:08 PM]] [('char_embeddings:0', [77, 100]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/weights:0', [5, 100, 200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/g:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-1/biases:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/weights:0', [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/g:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-1/biases:0', [200]),
 ('char_level/W_h-in-block-1:0', [1, 100, 200]),
 ('char_level/b_h-in-block-1:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/weights:0', [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/g:0', [200]),
 ('char_level/weightNorm-cnn-layer-1-in-block-2/biases:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/weights:0', [5, 200, 200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/g:0', [200]),
 ('char_level/weightNorm-cnn-layer-2-in-block-2/biases:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/weights:0', [3, 500, 300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/g:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-1/biases:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/weights:0', [3, 300, 300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/g:0', [300]),
 ('word_level/weightNorm-cnn-layer-2-in-block-1/biases:0', [300]),
 ('word_level/W_h-in-block-1:0', [1, 500, 300]),
 ('word_level/b_h-in-block-1:0', [300]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/weights:0', [3, 300, 250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/g:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-2/biases:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/weights:0', [3, 250, 250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/g:0', [250]),
 ('word_level/weightNorm-cnn-layer-2-in-block-2/biases:0', [250]),
 ('word_level/W_h-in-block-2:0', [1, 300, 250]),
 ('word_level/b_h-in-block-2:0', [250]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/weights:0', [3, 250, 200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/g:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-3/biases:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/weights:0', [3, 200, 200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/g:0', [200]),
 ('word_level/weightNorm-cnn-layer-2-in-block-3/biases:0', [200]),
 ('word_level/W_h-in-block-3:0', [1, 250, 200]),
 ('word_level/b_h-in-block-3:0', [200]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/weights:0', [3, 200, 150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/g:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-4/biases:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/weights:0', [3, 150, 150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/g:0', [150]),
 ('word_level/weightNorm-cnn-layer-2-in-block-4/biases:0', [150]),
 ('word_level/W_h-in-block-4:0', [1, 200, 150]),
 ('word_level/b_h-in-block-4:0', [150]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/weights:0', [3, 150, 100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/g:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-5/biases:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/weights:0', [3, 100, 100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/g:0', [100]),
 ('word_level/weightNorm-cnn-layer-2-in-block-5/biases:0', [100]),
 ('word_level/W_h-in-block-5:0', [1, 150, 100]),
 ('word_level/b_h-in-block-5:0', [100]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/weights:0', [3, 100, 50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/g:0', [50]),
 ('word_level/weightNorm-cnn-layer-1-in-block-6/biases:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/weights:0', [3, 50, 50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/g:0', [50]),
 ('word_level/weightNorm-cnn-layer-2-in-block-6/biases:0', [50]),
 ('word_level/W_h-in-block-6:0', [1, 100, 50]),
 ('word_level/b_h-in-block-6:0', [50]),
 ('output-layer/weights:0', [50, 3]),
 ('output-layer/biases:0', [3])]
[[11/15/2018 06:03:08 PM]] trainable parameter count:
[[11/15/2018 06:03:08 PM]] 2717403
[[11/15/2018 06:03:18 PM]] [[step        0]]     [[train]]     loss: 1.13642502       [[val]]     score: 0.0              
[[11/15/2018 06:03:20 PM]] [[step        1]]     [[train]]     loss: 0.87028995       [[val]]     score: 0.0              
[[11/15/2018 06:03:22 PM]] [[step        2]]     [[train]]     loss: 0.84212885       [[val]]     score: 0.0              
[[11/15/2018 06:03:24 PM]] [[step        3]]     [[train]]     loss: 0.82744862       [[val]]     score: 0.0              
[[11/15/2018 06:03:26 PM]] [[step        4]]     [[train]]     loss: 0.73514376       [[val]]     score: 0.0              
[[11/15/2018 06:03:28 PM]] [[step        5]]     [[train]]     loss: 0.66750266       [[val]]     score: 0.0              
[[11/15/2018 06:03:30 PM]] [[step        6]]     [[train]]     loss: 0.62082948       [[val]]     score: 0.0              
[[11/15/2018 06:03:32 PM]] [[step        7]]     [[train]]     loss: 0.57915566       [[val]]     score: 0.0              
[[11/15/2018 06:03:34 PM]] [[step        8]]     [[train]]     loss: 0.54527386       [[val]]     score: 0.0              
[[11/15/2018 06:03:36 PM]] [[step        9]]     [[train]]     loss: 0.51711844       [[val]]     score: 0.0              
[[11/15/2018 06:03:38 PM]] [[step       10]]     [[train]]     loss: 0.4906302        [[val]]     score: 0.0              
[[11/15/2018 06:03:40 PM]] [[step       11]]     [[train]]     loss: 0.47141421       [[val]]     score: 0.0508342        
[[11/15/2018 06:03:42 PM]] [[step       12]]     [[train]]     loss: 0.45011548       [[val]]     score: 0.09195006       
[[11/15/2018 06:03:44 PM]] [[step       13]]     [[train]]     loss: 0.43036353       [[val]]     score: 0.13213281       
[[11/15/2018 06:03:45 PM]] [[step       14]]     [[train]]     loss: 0.41018702       [[val]]     score: 0.17154543       
[[11/15/2018 06:03:47 PM]] [[step       15]]     [[train]]     loss: 0.39122706       [[val]]     score: 0.20972937       
[[11/15/2018 06:03:49 PM]] [[step       16]]     [[train]]     loss: 0.37258717       [[val]]     score: 0.24774066       
[[11/15/2018 06:03:51 PM]] [[step       17]]     [[train]]     loss: 0.3559707        [[val]]     score: 0.28414771       
[[11/15/2018 06:03:53 PM]] [[step       18]]     [[train]]     loss: 0.3396493        [[val]]     score: 0.31841969       
[[11/15/2018 06:03:55 PM]] [[step       19]]     [[train]]     loss: 0.32444198       [[val]]     score: 0.35004557       
[[11/15/2018 06:03:57 PM]] [[step       20]]     [[train]]     loss: 0.31043912       [[val]]     score: 0.37905137       
[[11/15/2018 06:03:59 PM]] [[step       21]]     [[train]]     loss: 0.29742835       [[val]]     score: 0.40552458       
[[11/15/2018 06:04:01 PM]] [[step       22]]     [[train]]     loss: 0.28540896       [[val]]     score: 0.42804522       
[[11/15/2018 06:04:03 PM]] [[step       23]]     [[train]]     loss: 0.27578301       [[val]]     score: 0.45047555       
[[11/15/2018 06:04:05 PM]] [[step       24]]     [[train]]     loss: 0.2650609        [[val]]     score: 0.46587425       
[[11/15/2018 06:04:07 PM]] [[step       25]]     [[train]]     loss: 0.25943765       [[val]]     score: 0.4828254        
[[11/15/2018 06:04:09 PM]] [[step       26]]     [[train]]     loss: 0.25154072       [[val]]     score: 0.48603673       
[[11/15/2018 06:04:11 PM]] [[step       27]]     [[train]]     loss: 0.2510096        [[val]]     score: 0.49758452       
[[11/15/2018 06:04:13 PM]] [[step       28]]     [[train]]     loss: 0.24402602       [[val]]     score: 0.51215705       
[[11/15/2018 06:04:14 PM]] [[step       29]]     [[train]]     loss: 0.2375231        [[val]]     score: 0.52669028       
[[11/15/2018 06:04:16 PM]] [[step       30]]     [[train]]     loss: 0.23056373       [[val]]     score: 0.54038105       
[[11/15/2018 06:04:18 PM]] [[step       31]]     [[train]]     loss: 0.22390418       [[val]]     score: 0.55360688       
[[11/15/2018 06:04:20 PM]] [[step       32]]     [[train]]     loss: 0.21782373       [[val]]     score: 0.56593346       
[[11/15/2018 06:04:22 PM]] [[step       33]]     [[train]]     loss: 0.21200106       [[val]]     score: 0.57759585       
[[11/15/2018 06:04:24 PM]] [[step       34]]     [[train]]     loss: 0.2072035        [[val]]     score: 0.58850048       
[[11/15/2018 06:04:26 PM]] [[step       35]]     [[train]]     loss: 0.20216881       [[val]]     score: 0.59881095       
[[11/15/2018 06:04:28 PM]] [[step       36]]     [[train]]     loss: 0.19753749       [[val]]     score: 0.60872043       
[[11/15/2018 06:04:30 PM]] [[step       37]]     [[train]]     loss: 0.19302631       [[val]]     score: 0.61819621       
[[11/15/2018 06:04:32 PM]] [[step       38]]     [[train]]     loss: 0.18848739       [[val]]     score: 0.62706445       
[[11/15/2018 06:04:34 PM]] [[step       39]]     [[train]]     loss: 0.18438764       [[val]]     score: 0.63577227       
[[11/15/2018 06:04:36 PM]] [[step       40]]     [[train]]     loss: 0.18028182       [[val]]     score: 0.64384351       
[[11/15/2018 06:04:38 PM]] [[step       41]]     [[train]]     loss: 0.17616946       [[val]]     score: 0.65165657       
[[11/15/2018 06:04:40 PM]] [[step       42]]     [[train]]     loss: 0.17265179       [[val]]     score: 0.65912657       
[[11/15/2018 06:04:42 PM]] [[step       43]]     [[train]]     loss: 0.16911408       [[val]]     score: 0.66609555       
[[11/15/2018 06:04:43 PM]] [[step       44]]     [[train]]     loss: 0.16579329       [[val]]     score: 0.67290322       
[[11/15/2018 06:04:45 PM]] [[step       45]]     [[train]]     loss: 0.16246222       [[val]]     score: 0.67935836       
[[11/15/2018 06:04:47 PM]] [[step       46]]     [[train]]     loss: 0.15957275       [[val]]     score: 0.68549793       
[[11/15/2018 06:04:49 PM]] [[step       47]]     [[train]]     loss: 0.15647861       [[val]]     score: 0.6913491        
[[11/15/2018 06:04:51 PM]] [[step       48]]     [[train]]     loss: 0.1533611        [[val]]     score: 0.69706546       
[[11/15/2018 06:04:53 PM]] [[step       49]]     [[train]]     loss: 0.15051203       [[val]]     score: 0.70250672       
[[11/15/2018 06:04:55 PM]] [[step       50]]     [[train]]     loss: 0.14806288       [[val]]     score: 0.70781081       
[[11/15/2018 06:04:57 PM]] [[step       51]]     [[train]]     loss: 0.14536316       [[val]]     score: 0.71290358       
[[11/15/2018 06:04:59 PM]] [[step       52]]     [[train]]     loss: 0.14287244       [[val]]     score: 0.71767853       
[[11/15/2018 06:05:01 PM]] [[step       53]]     [[train]]     loss: 0.14062848       [[val]]     score: 0.72250838       
[[11/15/2018 06:05:03 PM]] [[step       54]]     [[train]]     loss: 0.138125         [[val]]     score: 0.72718407       
[[11/15/2018 06:05:05 PM]] [[step       55]]     [[train]]     loss: 0.13626011       [[val]]     score: 0.73167823       
[[11/15/2018 06:05:07 PM]] [[step       56]]     [[train]]     loss: 0.13419328       [[val]]     score: 0.73601498       
[[11/15/2018 06:05:09 PM]] [[step       57]]     [[train]]     loss: 0.13197976       [[val]]     score: 0.74028999       
[[11/15/2018 06:05:11 PM]] [[step       58]]     [[train]]     loss: 0.12991485       [[val]]     score: 0.74440009       
[[11/15/2018 06:05:12 PM]] [[step       59]]     [[train]]     loss: 0.12792771       [[val]]     score: 0.74841873       
[[11/15/2018 06:05:14 PM]] [[step       60]]     [[train]]     loss: 0.12588917       [[val]]     score: 0.75220269       
[[11/15/2018 06:05:16 PM]] [[step       61]]     [[train]]     loss: 0.12402109       [[val]]     score: 0.75592155       
[[11/15/2018 06:05:18 PM]] [[step       62]]     [[train]]     loss: 0.12221805       [[val]]     score: 0.75959724       
[[11/15/2018 06:05:20 PM]] [[step       63]]     [[train]]     loss: 0.12058924       [[val]]     score: 0.76311484       
[[11/15/2018 06:05:22 PM]] [[step       64]]     [[train]]     loss: 0.11895207       [[val]]     score: 0.76654865       
